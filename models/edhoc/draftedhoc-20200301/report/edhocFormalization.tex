% !TEX root =  main.tex
Next we describe our approach towards formalizing the \mEdhoc{} protocol and list the properties we verify. %We used the
%symbolic (Dolev-Yao) model for verification, with \mTamarin{} for tool support.
%
%The next three subsections describe our threat model, briefly present the \mTamarin{} tool, and our modeling choices.
%
%Finally, we present the properties that we proved in this effort.
\subsection{Threat Model}\label{sec:threat-model}
We verify \mEdhoc{} in the symbolic Dolev-Yao model: as customary in this style of
modeling, we assume all cryptographic primitives to be ``perfect''. Encrypted messages can only be decrypted with the key, and no hash collisions exist. The attacker controls the
%, and hence
%only allow the attacker to encrypt and decrypt messages when they know the key,
%and exclude hash collisions, for example; the attacker is in control of the
 communication channel, and can interact with unbounded sessions of the protocol,
dropping, injecting and modifying messages at their liking.

We allow the attacker to impersonate
dishonest and/or compromised endpoints, by revealing their long-term and session
key material at any given point.
%
%Conversely, 
We say that a party is honest if they never reveal their
long-term key or session key material.

An important point is to define what the key material is.
    \mEdhoc{} does not result in an explicit session key, but a cryptographic
    state from which keys for \mOscore{} can be derived using \mHkdf.
    As will be seen later, depending on how the key material is defined, the
    different methods will have different authentication properties.
    %In particular, all methods except those where the initiator uses the
    %\mStat{} method provide a stronger form of authentication (injective
    %agreement) for the initiator.

\subsection{\mTamarin{}}
\label{sec:tamarin}
 
We chose \mTamarin{} to model and verify \mEdhoc{} in the symbolic model.
%
\mTamarin{} is an interactive verification tool based on multi-set rewriting rules
with event annotations based on action facts, which allow the user to check
 Linear Temporal Logic (LTL) formulas on these models.
%
Multi-set rewrite rules with action facts look like $ l \ifarrow[e] r $,
where $l$ and $r$ are multi-sets of facts, and $e$ is a multi-set of action facts.
Facts are $n$-ary predicates over a term algebra, which defines a set of function
symbols $\mathcal F$, variables $\mathcal V$ and names $\mathcal N$. \mTamarin{}
checks equality of these terms under an equational theory $E$. For example,
one can write $ dec(enc(x,y),y) =_E x $
to denote that symmetric decryption reverses the encryption operation under this theory.
The equational theory $E$ is fixed per model, and hence we omit the subscript.

In the presentation of the model we use some syntactic
sugar, namely
the use of let bindings (\mT{let ... in}). This is a series of
definitions of patterns which are substituted in the rest of the rule. \\

%\runhead{Semantics and Built-ins}
%%\subsubsection{Semantics and Built-ins} \phantom{} 
%\mTamarin{} states
%$S$, $S'$ are multisets of facts, and a semantic transition of the form $S \semarrow[E] S'$
%occurs if there is a rule $l \ifarrow[e] r$ and a substitution $\sigma$ such
%that $S \supseteq \sigma(l)$ and $S' = S \setminus \sigma(l) \uplus \sigma(r)$
%and $E = \sigma(e)$.
%
%There are a few more details, such as persistent facts which are denoted by a $!$
%and are never removed from the state.
%%
%The sorts fresh (denoted by $\sim$) and public (denoted by $\$$) denote fresh
%constants and public values known to the attacker respectively, and are both
%sub-sorts of a base sort.
%%
%Finally, \mTamarin{} has some built-in predicates ($\mIn,
%\mOut$ to represent input and output of messages with the attacker,
%and
%$\mFr$ to denote a fresh constant created in the current rule, among
%others), rules and equations that represent the attacker's knowledge
%and standard equational theories in the symbolic model,
%which we present later.

%\anote{This can go, I make a shorter note later:\\
%{Notational conventions} In the remainder of this section we present
%\mTamarin{} code as it appears in the models that we verify, in the style of
%literate programming.  Whenever possible we match the style of the protocol
%diagrams in Section~\ref{sec:edhoc} and the naming convention of the \mEdhoc{}
%\mSpec~\cite{selander-lake-edhoc-01}, so that each element of the model is
%traceable to the standard.  There are a few exceptions to this, most notably
%some variable names that we introduce for the sake of the \mTamarin{} model and are
%not present in the original \mSpec{}, which will appear in \mT{camelCase}, and
%the syntax for Diffie-Hellman exponentiation which is specific to \mTamarin{}.
%We also use \mT{xx} to name the ephemeral key for the initiator (resp. \mT{yy}
%for the responder) as to avoid confusion with \mTamarin's builtin variable
%names \mT{x} and \mT{y}.}

\runhead{Protocol rules and equations}
%\subsubsection{Protocol Rules and Equations}
\mTamarin{} allows users to define new function symbols and equational theories.
These user defined objects are then translated by \mTamarin{} into rewrite
rules, which are added to the set of considered rules during verification.
For example, in our model we have a symbol to denote authenticated encryption, for which \mTamarin{} produces the following rule:
%
\begin{lstlisting}
[!KU(k), !KU(m), !KU(ad), !KU(al)] --> [!KU(aeadEncrypt(k, m, ad, al))]
\end{lstlisting}
%
to denote that if the attacker knows a key \mT{k}, a message \mT{m}, the
authenticated data \mT{ad}, and an algorithm \mT{al}, then they can construct
the encryption using these parameters, and thus get to know the message
\lstinline{aeadEncrypt(k, m, ad, al)}.

In our model we make use of
the built-in theories of exclusive-or and DH operations, as in~\cite{DBLP:conf/csfw/DreierHRS18,DBLP:conf/csfw/SchmidtMCB12}.
%
%The XOR theory introduces the symbol \mT{XOR}, plus the necessary equational theory including associativity, commutativity, and inverse.
%
%The Diffie-Hellman theory introduces exponentiation \mT{g^y} and product of exponents \mT{x * y} as built-in symbols in the language, plus the necessary equational theory of associativity, commutativity, distributivity of exponentiation with product, and inverse.
For \mAead{} operations, we add the following equations:
\begin{lstlisting}
aeadDecrypt(k, aeadEncrypt(k, m, ad, al), ad, al) = m
decrypt(k, aeadEncrypt(k, m, ad, al), al) = m
\end{lstlisting}
Both the above equations govern decryption. The first rule checks to see if the authenticated data is as expected, while the second rule skips this check.


 
\subsection{Verified Properties}
\label{sec:desired-properties}

 
%\subsubsection{Secrecy}
\runhead{Secrecy}
We say that \mEdhoc{} satisfies secrecy of the established session key $sk$
between two honest parties $I$ and $R$ if, for any run of the protocol between $I$ and
$R$, the attacker does not get to know $sk$.\\
%
%The attacker may passively observe---and actively interfere with---the
%communication, and run any number of sessions with $A$ and $B$, in either role,
%concurrently or otherwise.

 
%\subsubsection{Authentication}
\runhead{Authentication}
\label{sec:authenticationDef}
Following Lowe~\cite{DBLP:conf/csfw/Lowe97a}, we say that a protocol guarantees to an
initiator $I$ injective agreement with a responder $R$ if, whenever $I$ believes
they have completed a run of the protocol with $R$, then $R$ has previously been
running the protocol with $I$ in these particular roles, and each such run of
$I$ corresponds to a unique run of $R$.

We model this slightly differently, as we show in Section~\ref{sec:propertyFormalization} later. In the lemma for guaranteeing injective agreement to $I$ with $R$, we enforce that for any session key $sk$, there can only be at most one run of $I$ involving it, and this run must map to at least one run of $R$ involving $sk$. The lemma for assuring injective agreement for $R$ with $I$ is formulated as the dual of this. This formulation uniquely guarantees one run of the initiator involving $sk$, but allows us to have potentially multiple runs of $R$ involving $sk$, and vice versa. However, because we prove injective agreement for both $I$ and $R$, this becomes equivalent to the Lowe formulation, and guarantees a unique map.

%To define \mEdhoc{}'s authentication properties we make use of Lowe's definition
%of \emph{injective agreement}~\cite{DBLP:conf/csfw/Lowe97a}:
%\knote{Maybe we don't need to quote the definition and could paraphrase it in a
%shorter form to save space.}
%\begin{quote}
%  ``We say that a protocol guarantees to an initiator $A$ [injective] agreement
%  with a responder $B$ on a set of data items $ds$ if, whenever $A$ (acting as
%  initiator) completes a run of the protocol, apparently with responder $B$,
%  then $B$ has previously been running the protocol, apparently with $A$, and
%  $B$ was acting as responder in his run, and the two agents agreed on the data
%  values corresponding to all the variables in $ds$, and each such run of $A$
%  corresponds to a unique run of $B$.''
%\end{quote}
%
We say that \mEdhoc{} in method $m$ satisfies \emph{explicit authentication} for
the initiator $I$ with a responder $R$, if injective agreement holds for $I$
with $R$ on the session key $sk$, when running method $m$.
%
The corresponding definition for the responder is analogous.
%
If both parties obtain explicit authentication we refer to it as mutual explicit
authentication (or simply explicit authentication).
%
A party $A$ is guaranteed explicit authentication when both parties have
agreement on fresh session key material, each others identities and roles
(and other parameters), when $A$ completes the protocol run.
%
Because they have (cryptographically justified) agreement on each others
identities, it follows that explicit authentication implies entity
authentication.
%
As we discuss later, it turned out that explicit authentication does not hold for all
\mEdhoc{} methods, in which cases we prove \emph{implicit authentication}.

Computational models often rely on implicit session key authentication
(see, for example, the definition of SK-security in the Canetti-Krawczyk
model~\cite{DBLP:conf/crypto/CanettiK02}).
%
Although symbolic models predominantly rely on correspondence properties
in the style of Lowe~\cite{DBLP:conf/csfw/Lowe97a}, there are examples where
implicit session key authentication has been used.
%
For example, Schmidt~et~al.~\cite{DBLP:conf/csfw/SchmidtMCB12} use a
symbolized version of an extended Canetti-Krawzcyk model.

%
We say that a protocol satisfies \emph{implicit authentication} if the
initiator and responder agree on the session key only after both parties
successfully completes the protocol.
%
That is, authentication is implicit, as the
initiator receives no confirmation that the responder has computed the same session key.
%
More precisely, we adapt the definition of~\cite{DBLP:journals/iacr/GuilhemFW19}
to the symbolic model, and we prove that if an initiator $I$ and a responder $R$
complete the protocol deriving the same session key, then $I$ believes they are
talking to $R$ and vice versa.
%

\mEdhoc{} claims to support mutual authentication with consistency, aliveness
and peer awareness (see Section~\ref{sec:claimedProperties}).
%
These claims appear to have been imported from \mSigma{}~\cite{sigma}, using the
inheritance argument, because all three appear there as well.
%
The definition of consistency~\cite{sigma} is very close in intent to the
definition we use for implicit authentication, except that it is posed in a
computational setting.
%
We therefore consider them equal in terms of intent for the purpose of this
paper.
%
Aliveness is, according to \mSigma{}~\cite{sigma}, guaranteed to a party $A$ if
after running the protocol with $B$, $A$ knows that $B$ was alive during
the execution, e.g., by verifying that $B$ signed a challenge.
%
For \mEdhoc{} this means that if we can prove mutual injective agreement, i.e.,
explicit authentication, on \mGxy{}, then mutual aliveness follows.
%
Peer awareness is informally defined in~\cite{sigma} as the guarantee
that if $A$ completes a protocol run with $B$, then not only does $A$
know that $B$ is alive, but also that $B$ has initiated a corresponding session
with $A$.
\\

\runhead{Session Key Material Independence}
%\subsubsection{Session Key Material Independence}
Session key material independence holds if knowing the key material for one
session does not give the attacker any information about the key material from
other sessions.  To model session
key material independence of \mEdhoc, we allow leaking session key material
after the protocol run, and verify secrecy for those sessions where the
session key material has not directly revealed to the attacker.
Would the attacker be able to break secrecy for one of those sessions after
learning session key material from another session, the key material would not 
be independent.\\

\runhead{Perfect Forward Secrecy (PFS)}
%\subsubsection{Perfect Forward Secrecy} 
Perfect forward
secrecy holds if, for any run in which the initiator and the responder
agree on a session key $sk$ and any of their long-term keys are revealed after
the run is complete, the attacker does still not learn $sk$.

 
%\subsubsection{Key-Compromise Impersonation} (KCI) This property takes the perspective of one
%of the endpoints of the protocol, say Alice running a session with Bob. A
%protocol is secure under KCI if Alice can still establish a secure session with
%Bob, even though Alice's keys are compromised at any time, and Bob's key
%material is not leaked until the end of the session.
%
% 
%\subsubsection{Post-Compromise Security} (PCS) A protocol that has
%\emph{post-compromise security} (following definitions in~\cite{cohn2016post})
%is capable of establishing a secure session even after one of the parties has
%been compromised. Cohn-Cordon et al.~\cite{cohn2016post} presents two notions of
%PCS, namely weak and strong PCS: here we focus on the latter.
%%
%A protocol guarantees \emph{weak PCS} if secrecy of any session key $sk$ holds
%between the initiator and the responder, even if the run of the protocol that
%established $sk$ happens after a \emph{limited compromise}, where the key
%material is not leaked, but the attacker is capable of impersonating both
%parties (i.e. has the ability to perform all cryptographic operations using the
%initiator's and responder's long term keys, but has not access to the long term
%keys).

 
%With the first rule we allow the protocol to decrypt the message \mT{m} if the encryption has matching key \mT{k}, authenticated data \mT{ad}, and uses the same algorithm \mT{al}.
%
%The second rule allows the attacker to decrypt the message \mT{m} with the key
%\mT{k} and without the authenticated data \mT{ad}, and hence skip the check.

%The built-in theories for XOR and Diffie-Hellman are a fair bit more complex
%than authenticated encryption, hence we refer to the original
%papers~\cite{DBLP:conf/csfw/DreierHRS18,DBLP:conf/csfw/SchmidtMCB12}
%for a full reference.
%

 
%\subsubsection{Syntactic Sugar} In the following presentation we use some syntactic
%sugar, namely
%the use of let bindings (\mT{let ... in}), which are series of
%definitions of patterns which are substituted in the rest of the rule. %Another
%prominent feature is the use of tuples (\mT{<t1, ..., tn>}) which are a
%built-in concept in \mTamarin.

%-------------------------------------------------------------------------- sub
\subsection{Modeling \mEdhoc{}}
\label{sec:modeling} 
In this section we detail the modeling choices that we have made for this formal
verification effort.
%
We model the five different methods of \mEdhoc{} from a single specification
using the M4 macro language to derive all valid combinations: \mPskPsk,
\mSigSig, \mSigStat, \mStatSig{} and \mStatStat.
%
Whenever possible we adhere with the variable names present in the \mSpec{} and
in Section~\ref{sec:edhoc}.
%
There are a few exceptions: we use \mT{camelCase} for names introduced in the modeling, and we use \mT{xx} and
\mT{yy} for the ephemeral keys, to avoid name clashes.
%
To keep the presentation brief, we only present the \mStatSig{} mode, as it
shows both asymmetric authentication methods at the same time.
%
%More details on the \mPskPsk{} method and 
All \mTamarin{} models can be
found at~\cite{edhocTamarinRepo}.
\\
%\anote{Fix: give a dropbox link instead of the repo}
%

%\subsubsection{General Setup}
\runhead{General Setup}
The following rules express the registering of the long term keys for the
\mSig{}- and \mStat{}-based methods, respectively.
%
\begin{lstlisting}
rule registerLTK_SIG:
 [Fr(~ltk)] --[ UniqLTK($A, ~ltk) ]->
  [!LTK_SIG($A, ~ltk), !PK_SIG($A, pk(~ltk)), Out(<!<$A, pk(~ltk)>!>)]
rule registerLTK_STAT:
 [Fr(~ltk)] --[ UniqLTK($A, 'g'^~ltk) ]->
  [!LTK_STAT($A, ~ltk), !PK_STAT($A, 'g'^~ltk), Out(<!<$A, 'g'^~ltk>!>)]
\end{lstlisting}
%
The rules \mT{registerLTK_SIG} and \mT{registerLTK_STAT} register a public key
(for signing and static DH exchange, respectively) which is tied to the
identity of an agent \mT{A}.
%
A similar rule \mT{registerLTK_PSK} registers pre-shared symmetric keys for
pairs of agents.
%
The event \mT{UniqLTK} together with a corresponding restriction models the fact that
the long-term key is unique for each agent.
% or pair of agents, as enforced by the following restriction:
% \begin{lstlisting}
% restriction uniqLTKs:
%     "All id k1 k2 #i #j. (UniqLTK(id, k1)@i & UniqLTK(id, k2)@j) ==> k1 = k2"
% \end{lstlisting}
This models that there is an external mechanism ensuring that the
long term keys are bound to the correct identity, e.g., a certificate authority.
%
It also models that the attacker cannot register new public keys for an
existing identity.
%

We also introduce rules to give the attacker access to
long-term keys and session keys.
%and the cryptographic interface of the device.
%
\begin{lstlisting}
rule revealLTK_SIG: [!LTK_SIG($A, ~ltk)] --[LTKRev($A)]-> [Out(~ltk)]
rule revealLTK_STAT: [!LTK_STAT($A, ~ltk)] --[LTKRev($A)]-> [Out(~ltk)]
rule revealSessionKeyI: [CommitI(tid, u, v, sk)] --[SKRev(sk)]-> [Out(sk)]
rule revealSessionKeyR: [CommitR(tid, u, v, sk)] --[SKRev(sk)]-> [Out(sk)]
\end{lstlisting}
%rule forge_SIG: [!LTK_SIG($A, ~ltk), In(xx)] --[TEE($A)]-> [Out(sign(xx, ~ltk))]
%rule exp_STAT: [!LTK_STAT($A, ~ltk), In('g'^x)] --[TEE($A)]-> [Out(('g'^x)^~ltk)]
%
These are used to model long-term key compromise and session key secrecy.
\\
%These rules allow to check Perfect Forward Secrecy, Key Compromise Impersonation
%and (weak) Post Compromise Security as defined in Section~\ref{sec:desired-properties},
%by giving the attacker the ability to access to long term and session keys, or
%to the cryptographic interface, at the appropriate time.

%\subsubsection{Modeling Choices}
\runhead{Modeling Choices}
We model each method of the protocol with four rules: \mT{I1}, \mT{R2}, \mT{I3}
and \mT{R4} (with the current method suffixed to the rule name).
%
Each of these represent one step of the protocol as run by the initiator \mT{I}
and the responder \mT{R}.
%
The rules can be traced back to the diagrams of
Figure~\ref{fig:edhocsigstat} and Figure~\ref{fig:edhocstatsig}.
%

Our model differs slightly from the \mSpec{}.
%
In particular, for convenience we divide the \mMethod{} element into two
elements, representing the method for the initiator and the responder without
reducing the attacker potential.
%
To make the model manageable we omit the connection identifiers \mCi{} and
\mCr{}, and represent the selected cipher suite by the public variable
\mT{\$cSUITES0}, known to the attacker.
%
We plan to introduce the connection identifiers in our ongoing verification
effort.
%
The way we model the selected cipher suite implies that our model does not
capture the possibility for the responder to reject the initiator's offer. 
%

%We model the XOR encryption of \mT{CIPHERTEXT_2} with the key \mT{K_2e} as to
%allow recovering of part of the key for known plaintext.
%
%Hence \mT{CIPHERTEXT_2} is not a direct XOR ``encryption'' in the model, but
%rather a tuple where each field is XORed with a half-key expansion (\mT{K_2e_1}
%and \mT{K_2e_2}).
We model the XOR encryption of \mT{CIPHERTEXT_2} with the key \mT{K_2e} using
\mTamarin{}'s built in theory for XOR, and allow each term of the encrypted
element to be attacked individually.
%
That is, we first expand \mT{K_2e} to as many key-stream terms as there are
terms in the plaintext tuple using the \mHkdfExpand{} function in a counter-mode
of operation.
%
We then XOR each term in the plaintext with its own key-stream term.
%
This models the \mSpec{} closer than if we would have XORed \mT{K_2e}, as a
single term, onto the plaintext tuple.
%
The XOR encryption can be seen in on line 16-19 in the listing of
\mT{R2_STAT_SIG} below.
%
\begin{lstlisting}
rule R2_STAT_SIG:
  let
    data_2 = <'g'^~yy>
    m1 = <'STAT', 'SIG', $cSUITE0, gx>
    TH_2 = h(<$cHash0, m1, data_2>)
    prk_2e = hkdfExtract('emptyStr', gx^~yy)
    prk_3e2m = prk_2e
    K_2m = hkdfExpand(<$cAEAD0, TH_2, 'K_2m'>, prk_3e2m)
    protected2 = $V // ID_CRED_V
    CRED_V = pkV
    extAad2 = <TH_2, CRED_V>
    assocData2 = <protected2, extAad2>
    MAC_2 = aeadEncrypt('emptyStr', K_2m, assocData2, $cAEAD0)
    authV = sign(<assocData2, MAC_2>, ~ltk)
    plainText2 = <$V, authV>
    K_2e = hkdfExpand(<$cAEAD0, TH_2, 'K_2e'>, prk_2e)
    K_2e_1 = hkdfExpand(<$cAEAD0, TH_2, 'K_2e', '1'>, prk_2e)
    K_2e_2 = hkdfExpand(<$cAEAD0, TH_2, 'K_2e', '2'>, prk_2e)
    CIPHERTEXT_2 = <$V XOR K_2e_1, authV XOR K_2e_2>
    m2 = <data_2, CIPHERTEXT_2>
    expSk = <gx^~yy>
 in
    [ !LTK_SIG($V, ~ltk)
    , !PK_SIG($V, pkV)
    , In(m1)
    , Fr(~yy)
    , Fr(~tid)
    ]
    --[ ExpRunningR(~tid, $V, expSk)
      , R2(~tid, $V, m1, m2)
      ]->
    [ StR2_STAT_SIG($V, ~ltk, ~yy, prk_3e2m, TH_2,
                    CIPHERTEXT_2, gx^~yy, ~tid, m1, m2)
    , Out(m2) ]
\end{lstlisting}

We use conventional state facts to save the internal state of a party between
executions of their rules.
%
%For instance, the fact \mbox{\mT{StI1_PSK_PSK($U, ~ltk, $V, ~xx, m1, ~tid)}}
%stores the initiator's internal state after executing the first step of the
%\mPskPsk{} method.
For instance, the fact
\mT{StR2_STAT_SIG} on lines 32 and 33
in the listing above stores the responder's internal state after executing the
second step of the \mStatSig{} method.
%
%\vnote{Is there any way to make these tildes in textsf show up ``normally''? Right now they're almost superscripted and it looks odd. Not high priority though.}
%\knote{I added a fix to the listings formatting. There was a jungle of
%font-specific hacks out there, not was perfect. This looks reasonable for a
%small work effort}

We mark some steps of the protocol with \mT{Running} action facts, e.g., line 29
above.
%
These facts represents that the party considers itself running the
protocol using certain parameters.
%
We mark other steps with \mT{Commit} action facts.
%
These facts represent that the party considers itself having
completed the protocol using a certain set of parameters.
%
For example, the fact \mT{ExpRunningR(~tid, \$V, expSk)} (line 29 above)
represent that a party is running a session and that they believe
they are playing the responder role, that their own identity is \mT{V}
and that \mT{expSk} is the session key.
%
Other facts like \mT{ExpCommitI(~tid, \$U, \$V, expSk)}
%
and \mT{CommitI(~tid, \$U, \$V, impSk)} represent that a party has completed
a session in the role of initiator, their own identity being \mT{U}, their
peer's identity being \mT{V} and the session key being \mT{expSk} and
\mT{impSk} respectively.
%
We use these action facts to model explicit and implicit authentication, as will
follow below.
%
The difference between the two \mT{Commit} action fact types is the choice of
key material on which we verify authentication (\mT{expSk} vs \mT{impSk}).
%
In the case of the \mSigSig{}, \mSigStat{} and \mPskPsk{} methods, these keys
are the same, but there will be a crucial difference when the initiator runs
the \mStat{} method.
%

We model the session key material differently for implicit authentication and
explicit authentication.
%
Specifically, when the initiator uses the \mStat{} authentication method,
\mT{impSk} includes the semi-static key \mGiy{}, whereas \mT{expSk} does not
include it.
%
The reason for this is that, when sending the second message \mMsgtwo{}, the
responder does not yet know the identity of the initiator and hence cannot
indicate knowledge of \mGiy{} to the initiator.
%
Because we want to verify strong properties such as explicit authentication
when possible, we collect those items in the key material referred to as
\mT{exp_k}.
%
When not possible we prove weaker properties for \mT{impSk}, which excludes
key material which it is even theoretically impossible to get explicit
authentication on.
%

What happens after a run of \mEdhoc{} completes is beyond the scope of our study, hence
we have left this part out of the modeling and focus on the key material
that forms the basis for the \mOscore{} security context.
%

%-------------------------------------------------------------------------- sub
\subsection{Property Formalization}
\label{sec:propertyFormalization}
In this section we present our formalization of the security properties. %into\\
%\mTamarin{} lemmas.
%
We refer to Section~\ref{sec:desired-properties} for a full explanation of the
properties.
\\

\runhead{Explicit Authentication}
We model explicit authentication between the initiator and the
responder in the form of mutual injective agreement on the session key material,
and on the roles and identities of the two parties.
%
We split the property into two lemmas, one for authenticating the responder to the
initiator, and one for the other direction.
%
For the first case, we use the action facts \mT{ExpCommitI} and
\mT{ExpRunningR}, and show that there is injective agreement
between the two action facts on the parameters identities \mT{U} and \mT{V},
their respective roles,  and the session key material \mT{expSk}.
%
The key material differs between \mEdhoc{} methods.
%

Additionally, we require that injective agreement must hold only when
no long-term key material for the two parties has been revealed before
the initiator completes the protocol run.
%
This is covered by the main disjunction in lines 10-12 on the right of
the implication.
%
That is, either we have injective agreement or one of
the three \mT{LtkRev} action facts must have been generated.
%

%lemma authInjAgreeGuaranteeForI:
%    all-traces
%    "All tidI u v expSk #i.
%         (ExpCommitI(tidI, u, v, expSk)@i
%	     & (All #j m1. I1(tidI, u, v, m1) @ j ==> (All #k. TEE(u)@k ==> k < j) & (All #k. TEE(v)@k ==> k < j))
%         & (All tidR #j m1 m2. R2(tidR, v, m1, m2) @ j ==> (All #k. TEE(u)@k ==> k < j) & (All #k. TEE(v)@k ==> k < j)))
%          ==>
%         ( ( (Ex tidR #j. ExpRunningR(tidR, v, expSk)@j & #j < #i)
%           & not(Ex tidI2 u2 v2 #i2. ExpCommitI(tidI2, u2, v2, expSk)@i2 & not(#i = #i2) ) )
%         | (Ex #j. LTKRev(v)@j & #j < #i) )"

% Code from July 22 commit
\begin{lstlisting}
lemma authInjAgreeGuaranteeForI:
     all-traces
     "All tidI u v expSk #i.
          ExpCommitI(tidI, u, v, expSk)@i ==>
          ( ( (Ex tidR #j. ExpRunningR(tidR, v, expSk)@j & #j < #i)
            & not( Ex tidI2 u2 v2 #i2. ExpCommitI(tidI2, u2, v2, expSk)@i2
                 & not(#i = #i2)
                 )
            )
          | (Ex #j. LTKRev(<u, v>)@j & #j < #i)
          | (Ex #j. LTKRev(u)@j & #j < #i)
          | (Ex #j. LTKRev(v)@j & #j < #i)
          )
     "
\end{lstlisting}
\knote{Please remind me again: how does this formula capture that there is only
    one unique responder session? We do check that the initiator session is
    unique, but not that the responder is.
}

Note that this property \emph{does not hold} when the initiator is
running the \mStat{} method, because the key material would then cover \mGiy{},
and as discussed above that is not possible.
%
For that case we need to prove implicit authentication, as detailed in
the next section.

Similarly to the previous lemma, we require that injective agreement also holds
in the reverse direction:
%
%\begin{lstlisting}
%lemma authInjAgreeGuaranteeForR:
%    all-traces
%    "All tidR u v sk #i.
%         (CommitR(tidR, u, v, sk)@i
%	     & (All tidI #j m1. I1(tidI, u, v, m1) @ j ==> (All #k. TEE(u)@k ==> k < j) & (All #k. TEE(v)@k ==> k < j))
%         & (All #j m1 m2. R2(tidR, v, m1, m2) @ j ==> (All #k. TEE(u)@k ==> k < j) & (All #k. TEE(v)@k ==> k < j)) )
%         ==>
%         ( ( (Ex tidI #j. ExpRunningI(tidI, u, v, sk)@j & #j < #i)
%           & not(Ex tidR2 u2 v2 #i2. ExpCommitR(tidR2, u2, v2, sk)@i2 & not(#i = #i2)) )
%         | (Ex #j. LTKRev(u)@j & #j < #i) )"
%\end{lstlisting}

% From commit on June 22
\begin{lstlisting}
lemma authInjAgreeGuaranteeForR:
    all-traces
    "All tidR u v sk #i.
         CommitR(tidR, u, v, sk)@i ==>
         ( ( (Ex tidI #j. RunningI(tidI, u, v, sk)@j & #j < #i)
           & not( Ex tidR2 u2 v2 #i2. CommitR(tidR2, u2, v2, sk)@i2
                & not(#i = #i2)
                )
           )
         | (Ex #j. LTKRev(<u, v>)@j & #j < #i)
         | (Ex #j. LTKRev(u)@j & #j < #i)
         | (Ex #j. LTKRev(v)@j & #j < #i)
         )
    "
\end{lstlisting}
%
The initiator is the first to complete the protocol run and confirms that
it knows both parties identities, their roles (based on message types) and the
session key in the third message.
%
In particular, the initiator knows the responder's identity, so even if the
responder uses the \mStat{} authentication, the knowledge asymmetry that caused
problems for injective agreement on \mGiy{} does not occur for \mGrx{}.
%
Therefore, the responder gets injective agreement guarantees, and hence explicit
authentication guarantees, for the entire session key material.
%
Consequently, we do not need to differentiate the explicit session key from the
implicit session key in this case and can ignore the \mT{Exp} prefix for the
running and commit action facts (\mT{RunningI} and \mT{CommitR} respectively).
%
\\

%\subsubsection{Implicit Authentication}
\runhead{Implicit Authentication}
The following lemma proves implicit authentication:
% \begin{lstlisting}
% lemma authGIYImplicitAuthGuaranteeForI:
%     all-traces
%     "All tidI u v impSk #i.
%          CommitI(tidI, u, v, impSk)@i ==>
%          ( ( (All tidR u2 v2 #j. CommitR(tidR, u2, v2, impSk)@j ==>
%                 (u = u2  &  v = v2)
%              )
%            &
%              (not Ex #k. K(impSk)@k)
%            &
%              (not( Ex tidR u v #j tidR2 u2 v2 #j2.
%                       ( CommitR(tidR,  u,  v,  impSk)@j
%                       & CommitR(tidR2, u2, v2, impSk)@j2
%                       & not(#j = #j2)
%                       )
%                  )
%              )
%            )
%          | (Ex #k. LTKRev(u)@k) | (Ex #k. TEE(u)@k)
%          | (Ex #k. LTKRev(v)@k) | (Ex #k. TEE(v)@k)
%          )
%          "
% \end{lstlisting}

\begin{lstlisting}
lemma authGIYImplicitAuthGuaranteeForI:
    all-traces
    "All tidI u v impSk #i.
         CommitI(tidI, u, v, impSk)@i ==>
         ( ( (All tidR u2 v2 #j. CommitR(tidR, u2, v2, impSk)@j ==>
                (u = u2  &  v = v2)
             )
           &
             (not Ex #k. K(impSk)@k)
           &
             (not( Ex tidR u v #j tidR2 u2 v2 #j2.
                      ( CommitR(tidR,  u,  v,  impSk)@j
                      & CommitR(tidR2, u2, v2, impSk)@j2
                      & not(#j = #j2)
                      )
                 )
             )
           )
         | (Ex #k. LTKRev(u)@k)
         | (Ex #k. LTKRev(v)@k)
         | (Ex #k. LTKRev(<u, v>)@k)
         )
    "
\end{lstlisting}
As opposed to lemma \mT{authInjAgreeGuaranteeForI}, here we prove that the two
parties implicitly authenticate on the key \mT{impSk}.
%
In this lemma we show that if any two parties (\mT{u} and \mT{v2} here) 
have completed a run of the protocol, and \mT{u} believes she is talking to
 \mT{v} and \mT{v2} believes he is talking to \mT{u2}, then their beliefs
match, i.e., \mT{u} = \mT{u2} and \mT{v} = \mT{v2}).
%
Furthermore there is an injective correspondence
between the \mT{CommitI} and \mT{CommitR} events, and the attacker does not
learn the session key material.
%
\\

%\subsubsection{Secrecy, Forward Secrecy and Session Key Independence}
\runhead{Secrecy, Forward Secrecy and Session Key Independence}
Finally, we prove secrecy of session key material, perfect forward secrecy
(PFS) and session key material independence.
%
All these properties are verified by proving the same lemma for each method,
as secrecy is a strictly weaker property than PFS (and hence follows
directly), and session key independence can be proven along PFS.
%
This is done by allowing the attacker to reveal long-term keys after either
the initiator or the responder have completed the protocol, and by
allowing the attacker to reveal session key material.
%
Despite these additional attacker capabilities, it still holds that the session
key material is secret for all the other runs of the protocol.
%
The lemma is as follows:
\begin{lstlisting}
lemma secrecyPFSGIYSessionKey:
	all-traces
    "(All tid u v sk #i #j. (K(sk)@i & CommitI(tid, u, v, sk)@j) ==>
            ((Ex #l. LTKRev(u)@l & #l < #j) | (Ex #l. LTKRev(v)@l & #l < #j) | (Ex #l. SKRev(sk)@l))
         )
         &
         (All tid u v sk #i #j. (K(sk)@i & CommitR(tid, u, v, sk)@j) ==>
            ((Ex #l. LTKRev(u)@l & #l < #j) | (Ex #l. LTKRev(v)@l & #l < #j) | (Ex #l. SKRev(sk)@l))
     )
    "
\end{lstlisting}
% We present the lemma for the \mSigStat{} method:
% \begin{lstlisting}
%   lemma secrecyPFSGIYSessionKey:
%         all-traces
%         "(All tid u v sk #i #j. (K(sk)@i & CommitI(tid, u, v, sk)@j) ==>
%             ((Ex #l. LTKRev(u)@l & #l < #j) | (Ex #l. LTKRev(v)@l & #l < #j) | (Ex #l. SKRev(sk)@l) | (Ex w #l. TEE(w)@l))
%          )
%          &
%          (All tid u v sk #i #j. (K(sk)@i & CommitR(tid, u, v, sk)@j) ==>
%             ((Ex #l. LTKRev(u)@l & #l < #j) | (Ex #l. LTKRev(v)@l & #l < #j) | (Ex #l. SKRev(sk)@l) | (Ex w #l. TEE(w)@l))
%             )"
% \end{lstlisting}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
