% !TEX root =  main.tex
 
Next we describe our approach towards formalizing the \mEdhoc{} protocol and list the properties we verify. %We used the
%symbolic (Dolev-Yao) model for verification, with \mTamarin{} for tool support.
%
%The next three subsections describe our threat model, briefly present the \mTamarin{} tool, and our modeling choices.
%
%Finally, we present the properties that we proved in this effort.
\subsection{Threat Model}\label{sec:threat-model}
We verify \mEdhoc{} in the symbolic Dolev-Yao model: as customary in this style of
modeling, we assume all cryptographic primitives to be ``perfect''. Encrypted messages can only be decrypted with the key, and no hash collisions exist. The attacker controls the
%, and hence
%only allow the attacker to encrypt and decrypt messages when they know the key,
%and exclude hash collisions, for example; the attacker is in control of the
 communication channel, and can interact with unbounded sessions of the protocol,
dropping, injecting and modifying messages at their liking.

One important point of the modeling is that we allow the attacker to impersonate
dishonest and/or compromised endpoints, by revealing their long-term and session
key material at any given point.
%
%Conversely, 
We say that a party is honest if they never reveal their
long-term key or session key material.

An important point is to define what the key material is.
    \mEdhoc{} does not result in an explicit session key, but a cryptographic
    state from which keys for \mOscore{} can be derived using \mHkdf.
    As will be seen later, depending on how the key material is defined, the
    different methods will have different authentication properties.
    %In particular, all methods except those where the initiator uses the
    %\mStat{} method provide a stronger form of authentication (injective
    %agreement) for the initiator.

\subsection{\mTamarin{}}
\label{sec:tamarin}
 
We chose \mTamarin{} to model and verify \mEdhoc{} in the symbolic model.
%
\mTamarin{} is an interactive verification tool based on multi-set rewriting rules
with event annotations, which allow the user to check Linear Temporal Logic
(LTL) formulas on these models.
%
Multi-set rewrite rules with events look like $ l \ifarrow[e] r $,
where $l$ and $r$ are multi-sets of facts, and $e$ is a multi-set of events.
Facts are $n$-ary predicates over a term algebra, which defines a set of function
symbols $\mathcal F$, variables $\mathcal V$ and names $\mathcal N$. \mTamarin{}
checks equality of these terms under an equational theory $E$. For example,
one can write $ dec(enc(x,y),y) =_E x $
to denote that symmetric decryption reverses the encryption operation under this theory.
The equational theory $E$ is fixed per model, and hence we omit the subscript.

In the presentation of the model we use some syntactic
sugar, namely
the use of let bindings (\mT{let ... in}). This is a series of
definitions of patterns which are substituted in the rest of the rule. \\

%\runhead{Semantics and Built-ins}
%%\subsubsection{Semantics and Built-ins} \phantom{} 
%\mTamarin{} states
%$S$, $S'$ are multisets of facts, and a semantic transition of the form $S \semarrow[E] S'$
%occurs if there is a rule $l \ifarrow[e] r$ and a substitution $\sigma$ such
%that $S \supseteq \sigma(l)$ and $S' = S \setminus \sigma(l) \uplus \sigma(r)$
%and $E = \sigma(e)$.
%
%There are a few more details, such as persistent facts which are denoted by a $!$
%and are never removed from the state.
%%
%The sorts fresh (denoted by $\sim$) and public (denoted by $\$$) denote fresh
%constants and public values known to the attacker respectively, and are both
%sub-sorts of a base sort.
%%
%Finally, \mTamarin{} has some built-in predicates ($\mIn,
%\mOut$ to represent input and output of messages with the attacker,
%and
%$\mFr$ to denote a fresh constant created in the current rule, among
%others), rules and equations that represent the attacker's knowledge
%and standard equational theories in the symbolic model,
%which we present later.

%\anote{This can go, I make a shorter note later:\\
%{Notational conventions} In the remainder of this section we present
%\mTamarin{} code as it appears in the models that we verify, in the style of
%literate programming.  Whenever possible we match the style of the protocol
%diagrams in Section~\ref{sec:edhoc} and the naming convention of the \mEdhoc{}
%\mSpec~\cite{selander-lake-edhoc-01}, so that each element of the model is
%traceable to the standard.  There are a few exceptions to this, most notably
%some variable names that we introduce for the sake of the \mTamarin{} model and are
%not present in the original \mSpec{}, which will appear in \mT{camelCase}, and
%the syntax for Diffie-Hellman exponentiation which is specific to \mTamarin{}.
%We also use \mT{xx} to name the ephemeral key for the initiator (resp. \mT{yy}
%for the responder) as to avoid confusion with \mTamarin's builtin variable
%names \mT{x} and \mT{y}.}

\runhead{Protocol rules and equations} 
%\subsubsection{Protocol Rules and Equations}
\mTamarin{} allows users to define new function symbols and equational theories.
These user defined objects are then translated by \mTamarin{} into rewrite
rules, which are added to the set of considered rules during verification.
For example, in our model we have a symbol to denote authenticated encryption, for which \mTamarin{} produces the following rule:
%
\begin{lstlisting}
[!KU(k), !KU(m), !KU(ad), !KU(al)] --> [!KU(aeadEncrypt(k, m, ad, al))]
\end{lstlisting}
%
to denote that if the attacker knows a key \mT{k}, a message \mT{m}, the
authenticated data \mT{ad}, and an algorithm \mT{al}, then they can construct
the encryption using these parameters, and thus get to know the message
\lstinline{aeadEncrypt(k, m, ad, al)}.

In our model we make use of
the built-in theories of exclusive-or and DH operations, as in~\cite{DBLP:conf/csfw/DreierHRS18,DBLP:conf/csfw/SchmidtMCB12}.
%
%The XOR theory introduces the symbol \mT{XOR}, plus the necessary equational theory including associativity, commutativity, and inverse.
%
%The Diffie-Hellman theory introduces exponentiation \mT{g^y} and product of exponents \mT{x * y} as built-in symbols in the language, plus the necessary equational theory of associativity, commutativity, distributivity of exponentiation with product, and inverse.
For \mAead{} operations, we add the following equations:
\begin{lstlisting}
aeadDecrypt(k, aeadEncrypt(k, m, ad, al), ad, al) = m
decrypt(k, aeadEncrypt(k, m, ad, al), al) = m
\end{lstlisting}
Both the above equations govern decryption. The first rule checks to see if the authenticated data is as expected, while the second rule skips this check.


 
\subsection{Verified Properties}
\label{sec:desired-properties}

 
%\subsubsection{Secrecy}
\runhead{Secrecy}
We say that \mEdhoc{} satisfies secrecy of the established session key $sk$
between two honest parties $I$ and $R$ if, for any run of the protocol between $I$ and
$R$, the attacker does not get to know $sk$.\\
%
%The attacker may passively observe---and actively interfere with---the
%communication, and run any number of sessions with $A$ and $B$, in either role,
%concurrently or otherwise.

 
%\subsubsection{Authentication}
\runhead{Authentication}
\label{sec:authenticationDef}
Following~\cite{DBLP:conf/csfw/Lowe97a}, we say that a protocol guarantees to an
initiator $I$ injective agreement with a responder $R$ if, whenever $I$ believes
they have completed a run of the protocol with $R$, then $R$ has previously been
running the protocol with $I$ in these particular roles, and each such run of
$I$ corresponds to a unique run of $R$.

%To define \mEdhoc{}'s authentication properties we make use of Lowe's definition
%of \emph{injective agreement}~\cite{DBLP:conf/csfw/Lowe97a}:
%\knote{Maybe we don't need to quote the definition and could paraphrase it in a
%shorter form to save space.}
%\begin{quote}
%  ``We say that a protocol guarantees to an initiator $A$ [injective] agreement
%  with a responder $B$ on a set of data items $ds$ if, whenever $A$ (acting as
%  initiator) completes a run of the protocol, apparently with responder $B$,
%  then $B$ has previously been running the protocol, apparently with $A$, and
%  $B$ was acting as responder in his run, and the two agents agreed on the data
%  values corresponding to all the variables in $ds$, and each such run of $A$
%  corresponds to a unique run of $B$.''
%\end{quote}
%
We say that \mEdhoc{} in method $m$ satisfies \emph{explicit authentication} for
the initiator $I$ with a responder $R$, if injective agreement holds for $I$
with $R$ on the session key $sk$, when running method $m$.
%
The corresponding definition for the responder is analogous.
%
If both parties obtain explicit authentication we refer to it as mutual explicit
authentication (or simply explicit authentication).

A party $A$ is guaranteed explicit authentication when both parties agree
on the session key (and other parameters), when $A$ completes the protocol
run.
%
As we discuss later, it turned out that explicit authentication does not hold for all
\mEdhoc{} methods, in which cases we prove \emph{implicit authentication}.

Computational models often rely on implicit session key authentication
(see, for example, the definition of SK-security in the Canetti-Krawczyk
model~\cite{DBLP:conf/crypto/CanettiK02}).
%
Although symbolic models predominantly rely on correspondence properties
in the style of Lowe~\cite{DBLP:conf/csfw/Lowe97a}, there are examples where
implicit session key authentication has been used.
%
For example, Schmidt~et~al.~\cite{DBLP:conf/csfw/SchmidtMCB12} use a
symbolized version of an extended Canetti-Krawzcyk model.

%
We say that a protocol satisfies \emph{implicit authentication} if the
initiator and responder agree on the session key only after a successful
execution of the protocol.
%
That is, authentication is implicit, as the
initiator receives no confirmation that the responder has computed the same session key.
%
More precisely, we adapt the definition of~\cite{DBLP:journals/iacr/GuilhemFW19}
to the symbolic model, and we prove that if an initiator $I$ and a responder $R$
complete the protocol deriving the same session key, then $I$ believes they are
talking to $R$ and vice versa.\\

\runhead{Session independence} 
%\subsubsection{Session Independence}
Session independence holds if knowing one session key does
not give the attacker any information about other sessions.  To model session
key independence of \mEdhoc, we allow leakage of session keys, and 
check security only of those sessions for which the keys have not been
directly revealed to the attacker.\\

\runhead{Perfect forward secrecy (PFS)}
%\subsubsection{Perfect Forward Secrecy} 
Perfect forward
secrecy holds if, for any run in which the initiator and the responder
agree on a session key $sk$, the attacker does not learn $sk$, even when the
long-term keys are revealed after completing the session.

 
%\subsubsection{Key-Compromise Impersonation} (KCI) This property takes the perspective of one
%of the endpoints of the protocol, say Alice running a session with Bob. A
%protocol is secure under KCI if Alice can still establish a secure session with
%Bob, even though Alice's keys are compromised at any time, and Bob's key
%material is not leaked until the end of the session.
%
% 
%\subsubsection{Post-Compromise Security} (PCS) A protocol that has
%\emph{post-compromise security} (following definitions in~\cite{cohn2016post})
%is capable of establishing a secure session even after one of the parties has
%been compromised. Cohn-Cordon et al.~\cite{cohn2016post} presents two notions of
%PCS, namely weak and strong PCS: here we focus on the latter.
%%
%A protocol guarantees \emph{weak PCS} if secrecy of any session key $sk$ holds
%between the initiator and the responder, even if the run of the protocol that
%established $sk$ happens after a \emph{limited compromise}, where the key
%material is not leaked, but the attacker is capable of impersonating both
%parties (i.e. has the ability to perform all cryptographic operations using the
%initiator's and responder's long term keys, but has not access to the long term
%keys).

 
%With the first rule we allow the protocol to decrypt the message \mT{m} if the encryption has matching key \mT{k}, authenticated data \mT{ad}, and uses the same algorithm \mT{al}.
%
%The second rule allows the attacker to decrypt the message \mT{m} with the key
%\mT{k} and without the authenticated data \mT{ad}, and hence skip the check.

%The built-in theories for XOR and Diffie-Hellman are a fair bit more complex
%than authenticated encryption, hence we refer to the original
%papers~\cite{DBLP:conf/csfw/DreierHRS18,DBLP:conf/csfw/SchmidtMCB12}
%for a full reference.
%

 
%\subsubsection{Syntactic Sugar} In the following presentation we use some syntactic
%sugar, namely
%the use of let bindings (\mT{let ... in}), which are series of
%definitions of patterns which are substituted in the rest of the rule. %Another
%prominent feature is the use of tuples (\mT{<t1, ..., tn>}) which are a
%built-in concept in \mTamarin.

%-------------------------------------------------------------------------- sub
\subsection{Modeling \mEdhoc{}}
\label{sec:modeling} 
In this section we detail the modeling choices that we have made for this formal
verification effort.
%
We model the five different methods of \mEdhoc{} from a single specification
using the M4 macro language to derive all valid combinations: \mPskPsk,
\mSigSig, \mSigStat, \mStatSig{} and \mStatStat.
%
Whenever possible we adhere with the variable names present in the \mSpec{} and
in Section~\ref{sec:edhoc}.
%
There are a few exceptions: we use \mT{camelCase} for those names the modeling
introduces, and we use \mT{xx} and
\mT{yy} for the ephemeral keys, to avoid name clashes.
%
To keep the presentation brief, we only present the \mStatSig{} mode, as it
shows both asymmetric authentication methods at the same time.
%
More details on the \mPskPsk{} method and all \mTamarin{} models can be
found through this link~\cite{edhocTamarinRepo}.
\\
\anote{Fix: give a dropbox link instead of the repo}
%

%\subsubsection{General Setup}
\runhead{General Setup}
The following rules express the registering of the long term keys for the
\mSig{}- and \mStat{}-methods, respectively.
%
\begin{lstlisting}
rule registerLTK_SIG:
 [Fr(~ltk)] --[ UniqLTK($A, ~ltk) ]->
  [!LTK_SIG($A, ~ltk), !PK_SIG($A, pk(~ltk)), Out(<!<$A, pk(~ltk)>!>)]
rule registerLTK_STAT:
 [Fr(~ltk)] --[ UniqLTK($A, 'g'^~ltk) ]->
  [!LTK_STAT($A, ~ltk), !PK_STAT($A, 'g'^~ltk), Out(<!<$A, 'g'^~ltk>!>)]
\end{lstlisting}
%
The rules \mT{registerLTK_SIG} and \mT{registerLTK_STAT} register a public key
(for signing and static DH exchange, respectively) that are tied to the
identity of an agent \mbox{\mT{A}.}
%
A similar rule \mT{registerLTK_PSK} registers pre-shared symmetric keys for
pairs of agents.
%
The event \mT{UniqLTK} together with a corresponding restriction models that
the long-term key is unique for each agent.
% or pair of agents, as enforced by the following restriction:
% \begin{lstlisting}
% restriction uniqLTKs:
%     "All id k1 k2 #i #j. (UniqLTK(id, k1)@i & UniqLTK(id, k2)@j) ==> k1 = k2"
% \end{lstlisting}
This models that there is an external mechanism ensuring that the
long term keys are bound to the correct identity, e.g., a certificate authority.
%
It also models that the attacker cannot register new public keys for an
existing identity.
%

In our model we introduce rules to give the attacker access to
long-term keys and session keys.
%and the cryptographic interface of the device.
%
\begin{lstlisting}
rule revealLTK_SIG: [!LTK_SIG($A, ~ltk)] --[LTKRev($A)]-> [Out(~ltk)]
rule revealLTK_STAT: [!LTK_STAT($A, ~ltk)] --[LTKRev($A)]-> [Out(~ltk)]
rule revealSessionKeyI: [CommitI(tid, u, v, sk)] --[SKRev(sk)]-> [Out(sk)]
rule revealSessionKeyR: [CommitR(tid, u, v, sk)] --[SKRev(sk)]-> [Out(sk)]
\end{lstlisting}
%rule forge_SIG: [!LTK_SIG($A, ~ltk), In(xx)] --[TEE($A)]-> [Out(sign(xx, ~ltk))]
%rule exp_STAT: [!LTK_STAT($A, ~ltk), In('g'^x)] --[TEE($A)]-> [Out(('g'^x)^~ltk)]
%
These are used to model long-term key compromise and session key secrecy.
\\
%These rules allow to check Perfect Forward Secrecy, Key Compromise Impersonation
%and (weak) Post Compromise Security as defined in Section~\ref{sec:desired-properties},
%by giving the attacker the ability to access to long term and session keys, or
%to the cryptographic interface, at the appropriate time.

%\subsubsection{Modeling Choices}
\runhead{Modeling Choices}
We model each method of the protocol with four rules: \mT{I1}, \mT{R2}, \mT{I3}
and \mT{R4} (with the current method suffixed to the rule name).
%
Each of these represent one step of the protocol as run by the initiator \mT{I}
and the responder \mT{R}.
%
The rules can be traced back to the diagrams of
Figure~\ref{fig:edhocsigstat} and Figure~\ref{fig:edhocstatsig}.
%

Our model differs slightly from the \mSpec{}.
%
In particular, for convenience we divide the \mMethod{} element into two
elements, representing the method for the initiator and the responder; this
does not reduce the attacker potential.
%
To make the model manageable we omit the connection identifiers \mCi{} and
\mCr{}, and represent the selected ciphersuite by the public variable
\mT{\$cSUITES0}, known to the attacker.
%
We plan to introduce the connection identifiers in our ongoing verification
effort.
%
The way we model the selected cipher suite implies that our model does not
capture the possibility for the responder to reject the initiator's offer.
%

%We model the XOR encryption of \mT{CIPHERTEXT_2} with the key \mT{K_2e} as to
%allow recovering of part of the key for known plaintext.
%
%Hence \mT{CIPHERTEXT_2} is not a direct XOR ``encryption'' in the model, but
%rather a tuple where each field is XORed with a half-key expansion (\mT{K_2e_1}
%and \mT{K_2e_2}).
We model the XOR encryption of \mT{CIPHERTEXT_2} with the key \mT{K_2e} using
\mTamarin{}'s built in theory for XOR, and allow each term of the encrypted
element to be attacked individually.
%
That is, we first expand \mT{K_2e} to as many key-stream terms as there are
terms in the plaintext tuple using the \mHkdfExpand{} function in a counter-mode
of operation.
%
We then XOR each term in the plaintext with its own key-stream term.
%
This models the \mSpec{} closer than if we would have XORed \mT{K_2e}, as a
single term, onto the plaintext tuple.
%
The XOR encryption can be seen in on line 16-19 in the listing of
\mT{R2_STAT_SIG} below.
%
\begin{lstlisting}
rule R2_STAT_SIG:
    let
          data_2 = <'g'^~yy>
          m1 = <'STAT', 'SIG', $cSUITE0, gx>
          TH_2 = h(<$cHash0, m1, data_2>)
          prk_2e = hkdfExtract('emptyStr', gx^~yy)
          prk_3e2m = prk_2e
          K_2m = hkdfExpand(<$cAEAD0, TH_2, 'K_2m'>, prk_3e2m)
          protected2 = $V // ID_CRED_V
          CRED_V = pkV
          extAad2 = <TH_2, CRED_V>
          assocData2 = <protected2, extAad2>
          MAC_2 = aeadEncrypt('emptyStr', K_2m, assocData2, $cAEAD0)
          authV = sign(<assocData2, MAC_2>, ~ltk)
          plainText2 = <$V, authV>
          K_2e = hkdfExpand(<$cAEAD0, TH_2, 'K_2e'>, prk_2e)
          K_2e_1 = hkdfExpand(<$cAEAD0, TH_2, 'K_2e', '1'>, prk_2e)
          K_2e_2 = hkdfExpand(<$cAEAD0, TH_2, 'K_2e', '2'>, prk_2e)
          CIPHERTEXT_2 = <$V XOR K_2e_1, authV XOR K_2e_2>
          m2 = <data_2, CIPHERTEXT_2>
          exp_sk = <gx^~yy>
   in
          [ !LTK_SIG($V, ~ltk)
          , !PK_SIG($V, pkV)
          , In(m1)
          , Fr(~yy)
          , Fr(~tid)
          ]
          --[ ExpRunningR(~tid, $V, exp_sk)
           , R2(~tid, $V, m1, m2)
            ]->
          [ StR2_STAT_SIG($V, ~ltk, ~yy, prk_3e2m, TH_2,
                          CIPHERTEXT_2, gx^~yy, ~tid, m1, m2)
          , Out(m2)
          ]
\end{lstlisting}

We use conventional state facts to save the internal state of a party between
executions of their rules.
%
%For instance, the fact \mbox{\mT{StI1_PSK_PSK($U, ~ltk, $V, ~xx, m1, ~tid)}}
%stores the initiator's internal state after executing the first step of the
%\mPskPsk{} method.
For instance, the fact
\mT{StR2_STAT_SIG} on lines 32 and 33
in the listing above stores the responder's internal state after executing the
second step of the \mStatSig{} method.
%

We mark some steps of the protocol with \mT{Running} action facts, e.g., line 29
above.
%
These facts represent that the party consider itself running the
protocol using certain parameters.
%
We mark other steps with \mT{Commit} action facts.
%
These facts represent that the party consider itself having
completed the protocol using a certain set of parameters.
%
For example, the fact \mT{ExpRunningR(~tid, \$V, exp_sk)} (line 29 above)
represent that a party is running a session and that they believe
they are doing so in the repsonder role, that their own identity is \mT{V}
and that \mT{exp_sk} is the session key.
%
Other facts like \mT{ExpCommitI(~tid, \$U, \$V, exp_sk)}
%
and \mT{CommitI(~tid, \$U, \$V, imp_sk)} represent that a party has completed
a session in the role of initiator, their own identity being \mT{U}, their
peer's identity being \mT{V} and the session key being \mT{exp_sk} and
\mT{imp_sk} respectively.
%
We use these action facts to model explicit and implicit authentication, as will
follow below.
%
The difference between the two \mT{Commit} action fact types is the choice of
key material on which we verify authentication (\mT{exp_sk} vs \mT{imp_sk}).
%
In the case of the \mSigSig{}, \mSigStat{} and \mPskPsk{} methods, these keys
are the same, but there will be a crucial difference when the initiator runs
the \mStat{} method.
%

We model the session key material differently for Implicit authentication and
explicit authentication.
%
Specifically, when the initiator uses the \mStat{} authentication method,
\mT{imp_sk} includes the semi-static key \mGiy{}, whereas \mT{exp_sk} does not
include it.
%
The reason for this is that, when sending the second message \mMsgtwo{}, the
responder does not yet know the identity of the initiator and can hence not
indicate knowledge of \mGiy{} to the initiator.
%
Because we want to verify strong properties such as explicit authentication
when possible, we collect those items in the key material referred to as
\mT{exp_k}.
%
When not possible we prove weaker properties for \mT{imp_sk}, which excludes
key material which it is even theoretically impossible to get explicit
authentication on.
%

What happens after \mEdhoc{} completes is beyond the scope of our study, hence
we have left this part out of the modeling and only focus on the key material
that is the bases for the \mOscore{} security context.
%

%-------------------------------------------------------------------------- sub
\subsection{Property Formalization}
\label{sec:propertyFormalization}
In this section we present how we formalized the security properties into
\mTamarin{} lemmas.
%
We refer to Section~\ref{sec:desired-properties} for a full explanation of the
properties.
\\

\runhead{Explicit Authentication}
We model explicit authentication between the initiator and the
responder in the form of mutual injective agreement on the session key material,
the roles and identities of the two parties.
%
We split the property in two lemmas, one for authenticating the responder to the
initiator, and one for the other direction.
%
For the first case, we use the events \mT{ExpCommitI} and
\mT{ExpRunningR}, and show that there is injective agreement
between the two events on the parameters \mT{tidI},
\mT{v} and the session key material \mT{expSk}
%
The key material differ between \mEdhoc{} methods.
%

Additionally, we require that injective agreement must hold only when
no long term key material for the two parties has been revealed before
the end of the protocol.
%
This is achieved by the main disjunction in lines 5-10 on the right of
the implication, requiring to reveal the long term keys (i.e. one of
the three \mT{LtkRev} events must trigger) if the responder has
not been running a matching session with the initiator.

\knote{We can remove the line "all-traces" from all listings to save space.
It is Tamarin's default. One only have to add "exists-trace" explicitly.}

%lemma authInjAgreeGuaranteeForI:
%    all-traces
%    "All tidI u v expSk #i.
%         (ExpCommitI(tidI, u, v, expSk)@i
%	     & (All #j m1. I1(tidI, u, v, m1) @ j ==> (All #k. TEE(u)@k ==> k < j) & (All #k. TEE(v)@k ==> k < j))
%         & (All tidR #j m1 m2. R2(tidR, v, m1, m2) @ j ==> (All #k. TEE(u)@k ==> k < j) & (All #k. TEE(v)@k ==> k < j)))
%          ==>
%         ( ( (Ex tidR #j. ExpRunningR(tidR, v, expSk)@j & #j < #i)
%           & not(Ex tidI2 u2 v2 #i2. ExpCommitI(tidI2, u2, v2, expSk)@i2 & not(#i = #i2) ) )
%         | (Ex #j. LTKRev(v)@j & #j < #i) )"

% Code from July 22 commit
\begin{lstlisting}
lemma authInjAgreeGuaranteeForI:
     all-traces
     "All tidI u v expSk #i.
          ExpCommitI(tidI, u, v, expSk)@i ==>
          ( ( (Ex tidR #j. ExpRunningR(tidR, v, expSk)@j & #j < #i)
            & not( Ex tidI2 u2 v2 #i2. ExpCommitI(tidI2, u2, v2, expSk)@i2
                 & not(#i = #i2)
                 )
            )
          | (Ex #j. LTKRev(<u, v>)@j & #j < #i)
          | (Ex #j. LTKRev(u)@j & #j < #i)
          | (Ex #j. LTKRev(v)@j & #j < #i)
          )
     "
\end{lstlisting}

Note that this property \emph{does not hold when} the initiator is
running the \mStat{} method.
%
For that case we need to prove implicit authentication, as detailed in
the next section.

Similarly to the previous lemma, we require that injective agreement also holds
in the reverse direction:

\begin{lstlisting}
lemma authInjAgreeGuaranteeForR:
    all-traces
    "All tidR u v sk #i.
         (CommitR(tidR, u, v, sk)@i
	     & (All tidI #j m1. I1(tidI, u, v, m1) @ j ==> (All #k. TEE(u)@k ==> k < j) & (All #k. TEE(v)@k ==> k < j))
         & (All #j m1 m2. R2(tidR, v, m1, m2) @ j ==> (All #k. TEE(u)@k ==> k < j) & (All #k. TEE(v)@k ==> k < j)) )
         ==>
         ( ( (Ex tidI #j. ExpRunningI(tidI, u, v, sk)@j & #j < #i)
           & not(Ex tidR2 u2 v2 #i2. ExpCommitR(tidR2, u2, v2, sk)@i2 & not(#i = #i2)) )
         | (Ex #j. LTKRev(u)@j & #j < #i) )"
\end{lstlisting}

As the explicit and implicit authentication always correspond for the
responder authenticating with the initiator, here we do not need the
additional \mT{Exp} prefix to the running and commit events
(\mT{CommitI} and \mT{CommitR} respectively).

 
\subsubsection{Implicit Authentication}

The following lemma proves implicit authentication:
\begin{lstlisting}
lemma authGIYImplicitAuthGuaranteeForI:
    all-traces
    "All tidI u v impSk #i.
         CommitI(tidI, u, v, impSk)@i ==>
         ( ( (All tidR u2 v2 #j. CommitR(tidR, u2, v2, impSk)@j ==>
                (u = u2  &  v = v2)
             )
           &
             (not Ex #k. K(impSk)@k)
           &
             (not( Ex tidR u v #j tidR2 u2 v2 #j2.
                      ( CommitR(tidR,  u,  v,  impSk)@j
                      & CommitR(tidR2, u2, v2, impSk)@j2
                      & not(#j = #j2)
                      )
                 )
             )
           )
         | (Ex #k. LTKRev(u)@k) | (Ex #k. TEE(u)@k)
         | (Ex #k. LTKRev(v)@k) | (Ex #k. TEE(v)@k)
         )
         "
\end{lstlisting}

As opposed to lemma \mT{authInjAgreeGuaranteeForI}, here we prove that the two
parties implicitly authenticate on the keys \mT{impSk}. %
In this lemma we show that if any two parties (\mT{u} and \mT{v2} here) complete
a run of the protocol, and \mT{u} believes she is talking to \mT{v} and \mT{v2}
believes he is talking to \mT{u2}, then their identities match (that is,
\mT{u = u2} and \mT{v = v2}). Furthermore there is an injective correspondence
between the \mT{CommitI} and \mT{CommitR} events, and the attacker does not
learn the session key material.

 
\subsubsection{Secrecy, Forward Secrecy and Session Key Independence}

Finally, we prove secrecy of session keys, perfect forward secrecy
(PFS) and session key independence.
%
All these properties are validated by a unique lemma for each method,
as secrecy is a strictly weaker property than PFS (and hence follows
directly), and session key independence can be proven along PFS.
%
This is done by allowing the revelation of long term keys after either
the initiator or the responder have completed the protocol, and by
allowing to reveal the session keys.
%
It still holds that the session keys are secret for all the other runs
of the protocol.

We present the lemma for the \mSigStat{} method:
\begin{lstlisting}
  lemma secrecyPFSGIYSessionKey:
        all-traces
        "(All tid u v sk #i #j. (K(sk)@i & CommitI(tid, u, v, sk)@j) ==>
            ((Ex #l. LTKRev(u)@l & #l < #j) | (Ex #l. LTKRev(v)@l & #l < #j) | (Ex #l. SKRev(sk)@l) | (Ex w #l. TEE(w)@l))
         )
         &
         (All tid u v sk #i #j. (K(sk)@i & CommitR(tid, u, v, sk)@j) ==>
            ((Ex #l. LTKRev(u)@l & #l < #j) | (Ex #l. LTKRev(v)@l & #l < #j) | (Ex #l. SKRev(sk)@l) | (Ex w #l. TEE(w)@l))
            )"
\end{lstlisting}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
